updated_data <- all_data_regions[,c(57, 1:2, 4:7, 12, 13,
17:21, 24, 31, 34, 35,
37:45, 47, 48, 50:55, 59)]
names(updated_data)
analysis_data <- updated_data[,c(1, 4:36)]
library(enmSdm)
library(randomForest)
library(caret) #for hyperparameter tuning
require(caTools)
library(pdp)
library(metrica)
library(iml)
library(vip)
table(analysis_data$name_region)
ncol(train)
names(analysis_data[ncol(analysis_data)])
rf_spatial_cv <- data.frame(model = rep("RF", 5),
region = unique(analysis_data$name_region)[i],
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != unique(analysis_data$name_region)[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == unique(analysis_data$name_region)[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_rf <- trainRf(data = train_complete,
resp = 'presence',
preds = 2:ncol(train_complete))
pred <- as.data.frame(predict(sdm_rf, newdata=test_complete[,-1], 'prob')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,2]), levels=c(1,2), auc = TRUE)
rf_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
rf_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_spatial_cv[i, "specificity"] <- specificity
rf_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
rf_spatial_cv[i, "oob_error"] <- sdm_rf$err.rate[500,1]
}
rf_spatial_cv <- data.frame(model = rep("RF", 5),
region = unique(analysis_data$name_region),
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != unique(analysis_data$name_region)[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == unique(analysis_data$name_region)[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_rf <- trainRf(data = train_complete,
resp = 'presence',
preds = 2:ncol(train_complete))
pred <- as.data.frame(predict(sdm_rf, newdata=test_complete[,-1], 'prob')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,2]), levels=c(1,2), auc = TRUE)
rf_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
rf_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_spatial_cv[i, "specificity"] <- specificity
rf_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
rf_spatial_cv[i, "oob_error"] <- sdm_rf$err.rate[500,1]
}
rf_spatial_cv
average(rf_spatial_cv$auc)
mean(rf_spatial_cv$auc)
rf_spatial_cv <- data.frame(model = rep("RF", 5),
region = unique(analysis_data$name_region),
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5),
presence = rep(NA, 5),
background = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != unique(analysis_data$name_region)[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == unique(analysis_data$name_region)[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_rf <- trainRf(data = train_complete,
resp = 'presence',
preds = 2:ncol(train_complete))
pred <- as.data.frame(predict(sdm_rf, newdata=test_complete[,-1], 'prob')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,2]), levels=c(1,2), auc = TRUE)
rf_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
rf_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_spatial_cv[i, "specificity"] <- specificity
rf_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
rf_spatial_cv[i, "oob_error"] <- sdm_rf$err.rate[500,1]
rf_spatial_cv[i, "presence"] <- nrow(subset(test, presence == 1))
rf_spatial_cv[i, "background"] <- nrow(subset(test, presence == 0))
}
rf_spatial_cv
unique(analysis_data$name_region)
unique(analysis_data$name_region)
regions <- unique(analysis_data$name_region)
rf_spatial_cv <- data.frame(model = rep("RF", 5),
region = regions,
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5),
presence = rep(NA, 5),
background = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != regions[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == regions[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_rf <- trainRf(data = train_complete,
resp = 'presence',
preds = 2:ncol(train_complete))
pred <- as.data.frame(predict(sdm_rf, newdata=test_complete[,-1], 'prob')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,2]), levels=c(1,2), auc = TRUE)
rf_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
rf_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_spatial_cv[i, "specificity"] <- specificity
rf_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
rf_spatial_cv[i, "oob_error"] <- sdm_rf$err.rate[500,1]
rf_spatial_cv[i, "presence"] <- nrow(subset(test, presence == 1))
rf_spatial_cv[i, "background"] <- nrow(subset(test, presence == 0))
}
rf_spatial_cv
brt_spatial_cv <- data.frame(model = rep("BRT", 5),
region = regions,
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5),
presence = rep(NA, 5),
background = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != regions[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == regions[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#remove missing data
train_complete <- train[complete.cases(train),] #; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),] #; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_brt <- trainBrt(data = train_complete,
resp = 'presence',
preds = names(train_complete)[2:ncol(train_complete)],#2:ncol(train_complete),
w = FALSE,
out = "model")
pred <- as.data.frame(predict(sdm_brt, newdata=test_complete[,-1], type = 'response')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,1]), auc = TRUE)
brt_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,1])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
brt_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
brt_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
brt_spatial_cv[i, "specificity"] <- specificity
brt_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
brt_spatial_cv[i, "presence"] <- nrow(subset(test, presence == 1))
brt_spatial_cv[i, "background"] <- nrow(subset(test, presence == 0))
}
brt_spatial_cv
mean(brt_spatial_cv$auc)
# install latest update from GitHub
remotes::install_github("rvalavi/blockCV", dependencies = TRUE)
library(blockCV)
??spatialAutoRange
?spatialBlock
?rangeExplorer()
env_data <- list.files(path="/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/env_data/national", pattern="tif", all.files=FALSE, full.names=TRUE,recursive=TRUE)
e <- raster::stack(env_data)
sac <- spatialAutoRange(rasterLayer = e,
sampleNumber = 10000,
doParallel = TRUE,
showPlots = TRUE)
sac <- spatialAutoRange(rasterLayer = e,
sampleNumber = 10000,
doParallel = TRUE,
showPlots = TRUE,
progress = TRUE)
env_data
env_data <- env_data[-26]
e <- raster::stack(env_data)
e
sac <- spatialAutoRange(rasterLayer = e,
sampleNumber = 100000000,
doParallel = TRUE,
showPlots = TRUE,
progress = TRUE)
sac <- spatialAutoRange(rasterLayer = e,
sampleNumber = 800000,
doParallel = TRUE,
showPlots = TRUE,
progress = TRUE)
pdp_vianna_se
pd_df_iter_leish <- read.csv('/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/shapley dependence study vianna sept 20 2022.csv'); names(pd_df_iter_leish)[2] <- 'Feature'
pd_df_iter_leish$row_code <- seq(1, nrow(pd_df_iter_leish), by = 1)
#split df into value & shap value; make each of them in long format; merge by feature and iteration
feature_value <- pd_df_iter_leish[,c(4:57,112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "value",
values_drop_na = FALSE)
feature_shap <- pd_df_iter_leish[,c(58:111, 112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "shap_val",
values_drop_na = FALSE)
feature_shap$feature <- substr(feature_shap$feature,1,nchar(feature_shap$feature)-2)
shap_pdp_df <- left_join(feature_value, feature_shap, by = c("feature","iter", "row_code")) #merge dfs again
vars_to_plot <- c("LitterSize","GR_Area_km2", "GestationLen_d", "NeonateBodyMass_g", "GR_MaxLong_dd") #subset to significant variables
shap_pdp_plot_df <- shap_pdp_df[shap_pdp_df$feature %in% vars_to_plot, ]
library(ggplot2)
library(tidyr)
library(dplyr)
library(sf)
library(raster)
library(foreach)
library(speciesgeocodeR)
pd_df_iter_leish <- read.csv('/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/shapley dependence study vianna sept 20 2022.csv'); names(pd_df_iter_leish)[2] <- 'Feature'
pd_df_iter_leish$row_code <- seq(1, nrow(pd_df_iter_leish), by = 1)
#split df into value & shap value; make each of them in long format; merge by feature and iteration
feature_value <- pd_df_iter_leish[,c(4:57,112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "value",
values_drop_na = FALSE)
feature_shap <- pd_df_iter_leish[,c(58:111, 112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "shap_val",
values_drop_na = FALSE)
feature_shap$feature <- substr(feature_shap$feature,1,nchar(feature_shap$feature)-2)
shap_pdp_df <- left_join(feature_value, feature_shap, by = c("feature","iter", "row_code")) #merge dfs again
vars_to_plot <- c("LitterSize","GR_Area_km2", "GestationLen_d", "NeonateBodyMass_g", "GR_MaxLong_dd") #subset to significant variables
shap_pdp_plot_df <- shap_pdp_df[shap_pdp_df$feature %in% vars_to_plot, ]
pdp_vianna_se <- ggplot(shap_pdp_plot_df, aes(x=value, y=shap_val)) +
#geom_point() +
ggtitle(expression(~italic(L. (Vianna))~" study effort")) +
stat_smooth(aes(group=iter), color='lightgrey', method='loess', size=0.5, se=FALSE) +
stat_smooth(aes(), method='loess', size=2, se=FALSE) +
geom_rug(data=shap_pdp_plot_df, aes(x=value), alpha=0.3, length=unit(0.05, "npc"), inherit.aes = FALSE, sides='b') +
facet_wrap(~feature, scales='free', ncol=4) +
theme_bw(base_size = 12) +
ylab("Shapley score") +
theme(legend.position = "none")
pdp_vianna_se
ggsave("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/vianna_studyEff_pdps.png", pdp_vianna_se, dpi=600)
library(sf)
sp_points <- read.csv("/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/raw_data/feature_collections/sp_snails/Ponto_Biom_SP_Final.csv")
head(sp_points)
sp_sf_object <- st_as_sf(sp_points, coords = c("Longitude", "Latitude"))
summary(sp_points)
sp_points <- sp_points[complete.cases(sp_points)$Longitude, ]
sp_points <- sp_points[complete.cases(sp_points$Longitude), ]
summary(sp_points)
sp_sf_object <- st_as_sf(sp_points, coords = c("Longitude", "Latitude"))
write_sf(sp_sf_object, "/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/raw_data/feature_collections/sp_snails/sp_snails.shp")
sp_sf_object
write_sf("/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/raw_data/feature_collections/sp_snails/sp_snails.shp", sp_sf_object)
sp_sf_object <- sp_sf_object[,1:21]
names(sp_sf_object)
names(sp_sf_object)[15:18] <- c("year_glabrata", "year_tenagophila", "year_straminea", "year_all")
write_sf(sp_sf_object, "/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/raw_data/feature_collections/sp_snails/sp_snails.shp")
########maps for Skinner et al. paper on VBD x Human Footprint
library(sf)
library(dplyr)
library(RColorBrewer)
library(dichromat)
library(ggplot2)
library(cmocean)
##------------------------------------##
##read in data & merge to shape files ##
##------------------------------------##
######read in data
data <- read.csv("/Users/carolineglidden/Desktop/forElle/full_dataset.csv"); names(data)[1] <- "CD_MUN_MoH"
mun <- st_read("/Users/carolineglidden/Documents/Leishmania/visceral leishmania spillover - master/machine learning model/raw data/br_municipios_20200807/BR_Municipios_2019.shp")
names(mun)[1] <- "CD_MUN_ibg"
#####match up CD using VL data
vl <- readRDS("/Users/carolineglidden/Documents/Leishmania/visceral leishmania spillover - master/machine learning model/cleaned data/vl data 2001 to 2019.rds")
vl <- unique(vl[, c("CD_MUN_MoH", "CD_MUN_ibg")]); data <- merge(data, vl, by = "CD_MUN_MoH"); mun <- merge(mun, vl, by = "CD_MUN_ibg")
#####attach variables to shape files
full_data <- merge(data, mun, by = 'CD_MUN_MoH')
##------------------------------------##
##covariate plots                     ## ##missing one municipality?
##------------------------------------##
##double check a few rows to make sure below function is correct
avg_human_footprint <- full_data %>%
group_by(CD_MUN_MoH) %>%
summarise(mean_HF = mean(human_footprint), across(.cols = geometry)) %>%
distinct()
hf <- ggplot(data = avg_human_footprint) +
geom_sf(aes(geometry=geometry, fill = mean_HF), col = "white", size=0) +
ggtitle('a. human footprint index') +
scale_fill_distiller(palette = "YlGnBu", direction = 1) +
theme_classic(base_size = 10) +
theme(legend.position = c(0.1, 0.25),
legend.title = element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank())
#ggsave("/Users/carolineglidden/Desktop/forElle/annual_human_footprint.tiff", hf)
avg_human_pop <- full_data %>%
group_by(CD_MUN_MoH) %>%
summarise(mean_pop = mean(population), across(.cols = geometry)) %>%
distinct()
pop <- ggplot(data = avg_human_pop) +
geom_sf(aes(geometry=geometry, fill = log(mean_pop)), col = "white", size=0) +
ggtitle('b. log(population size)') +
#scale_fill_distiller(palette = "YlGnBu", direction = 1) +
scale_fill_cmocean(name='dense') +
theme_classic(base_size = 10) +
theme(legend.position = c(0.1, 0.25),
legend.title = element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank())
#ggsave("/Users/carolineglidden/Desktop/forElle/annual_human_footprint.tiff", hf)
avg_annual_temp <- full_data %>%
group_by(CD_MUN_MoH) %>%
summarise(mean_tmp = mean(annual_tmp), across(.cols = geometry)) %>%
distinct()
temp <- ggplot(data = avg_annual_temp) +
geom_sf(aes(geometry=geometry, fill = mean_tmp), col = "white", size=0) +
ggtitle('c.annual temp') +
scale_fill_distiller(palette = "YlOrRd", direction = 1) +
theme_classic(base_size = 10) +
theme(legend.position = c(0.1, 0.25),
legend.title = element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank())
#ggsave("/Users/carolineglidden/Desktop/forElle/avg_annual_temp.tiff", temp)
avg_forest_cover <- full_data %>%
group_by(CD_MUN_MoH) %>%
summarise(mean_forest = mean(forest), across(.cols = geometry)) %>%
distinct()
frst <- ggplot(data = avg_forest_cover) +
geom_sf(aes(geometry=geometry, fill = mean_forest), col = "white", size=0) +
ggtitle('d. forest cover') +
scale_fill_cmocean(name='algae', start=0.1, end = 0.9) +
#scale_fill_distiller(palette = "Greens", direction = 1) +
theme_classic(base_size = 10) +
theme(legend.position = c(0.1, 0.25),
legend.title = element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank())
#ggsave("/Users/carolineglidden/Desktop/forElle/avg_forest_cover.tiff", frst)
all <- gridExtra::arrangeGrob(hf, pop, temp, frst, ncol=2)
#ggsave("/Users/carolineglidden/Desktop/forElle/vbd_hfi_plots/VBD_LULC_covariates.tiff", supp_all, units = 'in', width = 7, height = 7, dpi = 600)
ggsave("/Users/carolineglidden/Desktop/forElle/vbd_hfi_plots/VBD_LULC_covariates.pdf", supp_all, units = 'in', width = 7, height = 7, dpi = 600)
ggsave("/Users/carolineglidden/Desktop/forElle/vbd_hfi_plots/VBD_LULC_covariates.pdf", all, units = 'in', width = 7, height = 7, dpi = 600)
#load libraries
library(tidyr); library(dplyr); library(PerformanceAnalytics)
#-----------------------------------#
#read in datasets                   #
#-----------------------------------#
occ_data <- read.csv("data/final_passerine_dataset_Oct20_2022.csv")
mapbiomas <- read.csv("data/passerine_lulc_Oct2022.csv")
#human_population <- read.csv("data/passerine_population_Oct2022.csv") skipping this for now
#-----------------------------------#
#update label MAPBIOMAS classes     #
#-----------------------------------#
mapbiomas$class[mapbiomas$class == 3] <- "forest_formation"
mapbiomas$class[mapbiomas$class == 6] <- "flooded_forest"
mapbiomas$class[mapbiomas$class == 11] <- "wetland"
mapbiomas$class[mapbiomas$class == 12] <- "grassland"
mapbiomas$class[mapbiomas$class == 14] <- "farming"
mapbiomas$class[mapbiomas$class == 24] <- "urban"
mapbiomas$class[mapbiomas$class == 25] <- "other_non_vegetated"
mapbiomas$class[mapbiomas$class == 30] <- "mining"
mapbiomas$class[mapbiomas$class == 33] <- "river_lake_ocean"
#----------------------------------------------------------#
#summarize average area per class per point across years   #
#----------------------------------------------------------#
mapbiomas_mean <- mapbiomas %>%
group_by(row_code, class) %>%
summarise(mean_area = mean(area))
#----------------------------------------------------------#
#go from wide to long so each class is a unique column     #
#----------------------------------------------------------#
mapbiomas_mean_wide <- mapbiomas_mean %>%
pivot_wider(names_from = class, values_from = mean_area)
#change NAs to zero as NA means the landclass is not present
mapbiomas_mean_wide[is.na(mapbiomas_mean_wide)] <- 0
setwd("~/Documents/GitHub/UPCH-species-distribution-tutorial/R_code")
#load libraries
library(tidyr); library(dplyr); library(PerformanceAnalytics)
#-----------------------------------#
#read in datasets                   #
#-----------------------------------#
occ_data <- read.csv("data/final_passerine_dataset_Oct20_2022.csv")
mapbiomas <- read.csv("data/passerine_lulc_Oct2022.csv")
#human_population <- read.csv("data/passerine_population_Oct2022.csv") skipping this for now
#-----------------------------------#
#update label MAPBIOMAS classes     #
#-----------------------------------#
mapbiomas$class[mapbiomas$class == 3] <- "forest_formation"
mapbiomas$class[mapbiomas$class == 6] <- "flooded_forest"
mapbiomas$class[mapbiomas$class == 11] <- "wetland"
mapbiomas$class[mapbiomas$class == 12] <- "grassland"
mapbiomas$class[mapbiomas$class == 14] <- "farming"
mapbiomas$class[mapbiomas$class == 24] <- "urban"
mapbiomas$class[mapbiomas$class == 25] <- "other_non_vegetated"
mapbiomas$class[mapbiomas$class == 30] <- "mining"
mapbiomas$class[mapbiomas$class == 33] <- "river_lake_ocean"
#----------------------------------------------------------#
#summarize average area per class per point across years   #
#----------------------------------------------------------#
mapbiomas_mean <- mapbiomas %>%
group_by(row_code, class) %>%
summarise(mean_area = mean(area))
#----------------------------------------------------------#
#go from wide to long so each class is a unique column     #
#----------------------------------------------------------#
mapbiomas_mean_wide <- mapbiomas_mean %>%
pivot_wider(names_from = class, values_from = mean_area)
#change NAs to zero as NA means the landclass is not present
mapbiomas_mean_wide[is.na(mapbiomas_mean_wide)] <- 0
occ_data <- read.csv("data/final_passerine_dataset_Oct20_2022.csv")
dir()
occ_data <- read.csv("../data/final_passerine_dataset_Oct20_2022.csv")
mapbiomas <- read.csv("../data/passerine_lulc_Oct2022.csv")
#-----------------------------------#
#update label MAPBIOMAS classes     #
#-----------------------------------#
mapbiomas$class[mapbiomas$class == 3] <- "forest_formation"
mapbiomas$class[mapbiomas$class == 6] <- "flooded_forest"
mapbiomas$class[mapbiomas$class == 11] <- "wetland"
mapbiomas$class[mapbiomas$class == 12] <- "grassland"
mapbiomas$class[mapbiomas$class == 14] <- "farming"
mapbiomas$class[mapbiomas$class == 24] <- "urban"
mapbiomas$class[mapbiomas$class == 25] <- "other_non_vegetated"
mapbiomas$class[mapbiomas$class == 30] <- "mining"
mapbiomas$class[mapbiomas$class == 33] <- "river_lake_ocean"
#----------------------------------------------------------#
#summarize average area per class per point across years   #
#----------------------------------------------------------#
mapbiomas_mean <- mapbiomas %>%
group_by(row_code, class) %>%
summarise(mean_area = mean(area))
#----------------------------------------------------------#
#go from wide to long so each class is a unique column     #
#----------------------------------------------------------#
mapbiomas_mean_wide <- mapbiomas_mean %>%
pivot_wider(names_from = class, values_from = mean_area)
#change NAs to zero as NA means the landclass is not present
mapbiomas_mean_wide[is.na(mapbiomas_mean_wide)] <- 0
#--
write.csv("../data/passerine_lulc_clean_Oct2022.csv")
write.csv(mapbiomas_mean_wide, "../data/passerine_lulc_clean_Oct2022.csv")
