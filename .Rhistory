# Build target species rows
#------------------------------------------------------
# set target species
target_species_string <- 'glabrata' #, 'tenagophila', 'straminea'
occ.target <- environmental_covariate_df %>%
filter(species  == target_species_string) #%>% #filter by target species
#filter(!is.na(year)); #and remove NAs
#make lat/lon df to be read by thin() function
occ_target_lat_lon <- as.data.frame(occ.target[,c("species", "longitude", "latitude")]); occ_target_lat_lon$latitude <- as.numeric(occ_target_lat_lon$latitude); occ_target_lat_lon$longitude <- as.numeric(occ_target_lat_lon$longitude)
#new thinning procedure (AS: 07/17/2022)
rast <- raster("/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/env_data/national/bio4_temp_.tif")
#one point per grid cell
s <- gridSample(occ_target_lat_lon[2:3], rast, n=1)
thin.occ <- occ.target[row.names(s),]; thin.occ <- thin.occ[complete.cases(thin.occ), ] #283 obs w/out gbif & 307 w/gbif
thin.occ$presence <- 1
#------------------------------------------------------
# Build background species / background mask rows
#------------------------------------------------------
# Limit to background species (non target species, non wo specification)
bg_df <- environmental_covariate_df %>%
filter(!species %in% c(target_species_string, '', 'sp.'))
#table(bg_df$species)
#dim(bg_df)
# Read in template raster and list setup
bg_species_list <- unique(bg_df$species)
# Extract number of Insecta (+ supplemental) background points per grid cell (i.e., weighted bias mask)
bg_points <- bg_df %>% dplyr::select(c(longitude, latitude)) %>%
as.matrix()
bg_df$index <- c(1:dim(bg_df)[1])
bg_longlat <- cellFromXY(rast, bg_points) %>% as.data.frame() %>%
cbind(bg_df$year) %>%
cbind(bg_df$index) %>%
mutate(count = 1) %>% setNames(c("cell","year","index","count")) %>%
group_by(cell) %>% dplyr::summarize(count = sum(count),
max_year = max(year),
avg_year = mean(year),
max_index = max(index)) %>%
# arrange(desc(count)) %>%
mutate(longitude = xFromCell(rast, cell),  # Acquire longitude (x) and latitude (y) from cell centroids
latitude = yFromCell(rast, cell)) %>%
dplyr::select(-cell) %>% # Cell number is now obsolete, since will be working from (x,y) as an sf object
filter(!is.na(longitude) & !is.na(latitude)) # Remove the NA locations
#bg_longlat
#write.csv(bg_longlat, "~/Desktop/bgmask_glabrata.csv")
#bg_mask <- read.csv("bgmask_glabrata.csv")
# Build geometries
bg_mask_sf_full <- st_as_sf(bg_longlat, coords = c("longitude","latitude"),
agr = "constant", crs = 4326)
# Random sample bg without replacement from weighted bias mask at (1.5x occ) multiplier
set.seed(9)
multiplier <- 2
bg_mask_weights <- bg_mask_sf_full %>%
mutate(weight = count/sum(count))
bg_mask_df <- bg_mask_sf_full[sample(nrow(bg_mask_weights),
size = multiplier * nrow(thin.occ),
replace = FALSE,
prob = bg_mask_weights$weight),]
bg_final_data <- bg_df[bg_mask_df$max_index,]
bg_final_data$presence <- 0
#combine data
all_data <- rbind(thin.occ, bg_final_data[,-(ncol(bg_final_data)-1)])
#------------------------------------------------------
# Now remove highly correlated variables
#------------------------------------------------------
library(corrplot)
m <- cor(all_data[5:57])
corrplot(m, method="circle")
updated_data <- all_data[,c(59, 1:4, 6:9, 14, 15,
19:23, 26, 33, 36, 37,
39:47, 49, 50, 52:57)]
m2 <- cor(updated_data[6:32])
corrplot(m2, method="circle")
analysis_data <- updated_data[,c(1, 6:37)]
names(all_data)
brazil_regions <- geobr::read_region(year=2019, showProgress = FALSE)
brazil_regions
all_data_regions <- st_intersection(all_data_sf, brazil_regions)
all_data_sf <- st_as_sf(all_data, coords = c("longitude","latitude"),
agr = "constant", crs = 4326)
all_data_regions <- st_intersection(all_data_sf, brazil_regions)
crs(all_data_sf) <- crs(brazil_regions)
crs(brazil_regions)
crs(all_data_sf)
all_data_sf <- all_data_sf %>% st_set_crs(st_crs(brazil_regions))
all_data_regions <- st_intersection(all_data_sf, brazil_regions)
head(all_data_regions)
all_data_regions <- st_drop_geometry(all_data_regions)
head(all_data_regions)
names(all_data_regions)
updated_data <- all_data_regions[,c(57, 1:2, 4:7, 12, 13,
17:21, 24, 31, 34, 35,
37:45, 47, 48, 50:55, 59)]
names(updated_data)
analysis_data <- updated_data[,c(1, 4:36)]
library(enmSdm)
library(randomForest)
library(caret) #for hyperparameter tuning
require(caTools)
library(pdp)
library(metrica)
library(iml)
library(vip)
table(analysis_data$name_region)
ncol(train)
names(analysis_data[ncol(analysis_data)])
rf_spatial_cv <- data.frame(model = rep("RF", 5),
region = unique(analysis_data$name_region)[i],
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != unique(analysis_data$name_region)[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == unique(analysis_data$name_region)[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_rf <- trainRf(data = train_complete,
resp = 'presence',
preds = 2:ncol(train_complete))
pred <- as.data.frame(predict(sdm_rf, newdata=test_complete[,-1], 'prob')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,2]), levels=c(1,2), auc = TRUE)
rf_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
rf_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_spatial_cv[i, "specificity"] <- specificity
rf_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
rf_spatial_cv[i, "oob_error"] <- sdm_rf$err.rate[500,1]
}
rf_spatial_cv <- data.frame(model = rep("RF", 5),
region = unique(analysis_data$name_region),
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != unique(analysis_data$name_region)[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == unique(analysis_data$name_region)[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_rf <- trainRf(data = train_complete,
resp = 'presence',
preds = 2:ncol(train_complete))
pred <- as.data.frame(predict(sdm_rf, newdata=test_complete[,-1], 'prob')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,2]), levels=c(1,2), auc = TRUE)
rf_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
rf_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_spatial_cv[i, "specificity"] <- specificity
rf_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
rf_spatial_cv[i, "oob_error"] <- sdm_rf$err.rate[500,1]
}
rf_spatial_cv
average(rf_spatial_cv$auc)
mean(rf_spatial_cv$auc)
rf_spatial_cv <- data.frame(model = rep("RF", 5),
region = unique(analysis_data$name_region),
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5),
presence = rep(NA, 5),
background = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != unique(analysis_data$name_region)[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == unique(analysis_data$name_region)[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_rf <- trainRf(data = train_complete,
resp = 'presence',
preds = 2:ncol(train_complete))
pred <- as.data.frame(predict(sdm_rf, newdata=test_complete[,-1], 'prob')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,2]), levels=c(1,2), auc = TRUE)
rf_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
rf_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_spatial_cv[i, "specificity"] <- specificity
rf_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
rf_spatial_cv[i, "oob_error"] <- sdm_rf$err.rate[500,1]
rf_spatial_cv[i, "presence"] <- nrow(subset(test, presence == 1))
rf_spatial_cv[i, "background"] <- nrow(subset(test, presence == 0))
}
rf_spatial_cv
unique(analysis_data$name_region)
unique(analysis_data$name_region)
regions <- unique(analysis_data$name_region)
rf_spatial_cv <- data.frame(model = rep("RF", 5),
region = regions,
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5),
presence = rep(NA, 5),
background = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != regions[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == regions[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_rf <- trainRf(data = train_complete,
resp = 'presence',
preds = 2:ncol(train_complete))
pred <- as.data.frame(predict(sdm_rf, newdata=test_complete[,-1], 'prob')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,2]), levels=c(1,2), auc = TRUE)
rf_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
rf_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_spatial_cv[i, "specificity"] <- specificity
rf_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
rf_spatial_cv[i, "oob_error"] <- sdm_rf$err.rate[500,1]
rf_spatial_cv[i, "presence"] <- nrow(subset(test, presence == 1))
rf_spatial_cv[i, "background"] <- nrow(subset(test, presence == 0))
}
rf_spatial_cv
brt_spatial_cv <- data.frame(model = rep("BRT", 5),
region = regions,
auc = rep(NA, 5),
fscore = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
tss = rep(NA, 5),
oob_error = rep(NA, 5),
presence = rep(NA, 5),
background = rep(NA, 5))
for(i in 1:5){
set.seed(99)
rows <- sample(nrow(analysis_data))
analysis_data <- analysis_data[rows,]
#try stratified sampling
train <- subset(analysis_data, name_region != regions[i])
train <- train[,-ncol(train)] #takeout name_region
test  <- subset(analysis_data, name_region == regions[i])
test <- test[,-ncol(test)] #takeout name_region
#remove missing data
train_complete <- train[complete.cases(train),]; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),]; test_complete$presence <- as.factor(test_complete$presence)
#remove missing data
train_complete <- train[complete.cases(train),] #; train_complete$presence <- as.factor(train_complete$presence)
test_complete <- test[complete.cases(test),] #; test_complete$presence <- as.factor(test_complete$presence)
#run model
sdm_brt <- trainBrt(data = train_complete,
resp = 'presence',
preds = names(train_complete)[2:ncol(train_complete)],#2:ncol(train_complete),
w = FALSE,
out = "model")
pred <- as.data.frame(predict(sdm_brt, newdata=test_complete[,-1], type = 'response')) #take out response from test data
auc <- pROC::roc(response=as.numeric(test_complete[,1]), predictor=as.numeric(pred[,1]), auc = TRUE)
brt_spatial_cv[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,1])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
brt_spatial_cv[i, "fscore"] <- metrica::fscore(data = metrica.format, obs = labels, pred = predictions)$fscore
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
brt_spatial_cv[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
brt_spatial_cv[i, "specificity"] <- specificity
brt_spatial_cv[i, "tss"] <- sensitivity + specificity - 1
brt_spatial_cv[i, "presence"] <- nrow(subset(test, presence == 1))
brt_spatial_cv[i, "background"] <- nrow(subset(test, presence == 0))
}
brt_spatial_cv
mean(brt_spatial_cv$auc)
# install latest update from GitHub
remotes::install_github("rvalavi/blockCV", dependencies = TRUE)
library(blockCV)
??spatialAutoRange
?spatialBlock
?rangeExplorer()
env_data <- list.files(path="/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/env_data/national", pattern="tif", all.files=FALSE, full.names=TRUE,recursive=TRUE)
e <- raster::stack(env_data)
sac <- spatialAutoRange(rasterLayer = e,
sampleNumber = 10000,
doParallel = TRUE,
showPlots = TRUE)
sac <- spatialAutoRange(rasterLayer = e,
sampleNumber = 10000,
doParallel = TRUE,
showPlots = TRUE,
progress = TRUE)
env_data
env_data <- env_data[-26]
e <- raster::stack(env_data)
e
sac <- spatialAutoRange(rasterLayer = e,
sampleNumber = 100000000,
doParallel = TRUE,
showPlots = TRUE,
progress = TRUE)
sac <- spatialAutoRange(rasterLayer = e,
sampleNumber = 800000,
doParallel = TRUE,
showPlots = TRUE,
progress = TRUE)
pdp_vianna_se
pd_df_iter_leish <- read.csv('/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/shapley dependence study vianna sept 20 2022.csv'); names(pd_df_iter_leish)[2] <- 'Feature'
pd_df_iter_leish$row_code <- seq(1, nrow(pd_df_iter_leish), by = 1)
#split df into value & shap value; make each of them in long format; merge by feature and iteration
feature_value <- pd_df_iter_leish[,c(4:57,112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "value",
values_drop_na = FALSE)
feature_shap <- pd_df_iter_leish[,c(58:111, 112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "shap_val",
values_drop_na = FALSE)
feature_shap$feature <- substr(feature_shap$feature,1,nchar(feature_shap$feature)-2)
shap_pdp_df <- left_join(feature_value, feature_shap, by = c("feature","iter", "row_code")) #merge dfs again
vars_to_plot <- c("LitterSize","GR_Area_km2", "GestationLen_d", "NeonateBodyMass_g", "GR_MaxLong_dd") #subset to significant variables
shap_pdp_plot_df <- shap_pdp_df[shap_pdp_df$feature %in% vars_to_plot, ]
library(ggplot2)
library(tidyr)
library(dplyr)
library(sf)
library(raster)
library(foreach)
library(speciesgeocodeR)
pd_df_iter_leish <- read.csv('/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/shapley dependence study vianna sept 20 2022.csv'); names(pd_df_iter_leish)[2] <- 'Feature'
pd_df_iter_leish$row_code <- seq(1, nrow(pd_df_iter_leish), by = 1)
#split df into value & shap value; make each of them in long format; merge by feature and iteration
feature_value <- pd_df_iter_leish[,c(4:57,112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "value",
values_drop_na = FALSE)
feature_shap <- pd_df_iter_leish[,c(58:111, 112, 113)] %>%
tidyr::pivot_longer(cols = 1:53, #check this
names_to = "feature",
values_to = "shap_val",
values_drop_na = FALSE)
feature_shap$feature <- substr(feature_shap$feature,1,nchar(feature_shap$feature)-2)
shap_pdp_df <- left_join(feature_value, feature_shap, by = c("feature","iter", "row_code")) #merge dfs again
vars_to_plot <- c("LitterSize","GR_Area_km2", "GestationLen_d", "NeonateBodyMass_g", "GR_MaxLong_dd") #subset to significant variables
shap_pdp_plot_df <- shap_pdp_df[shap_pdp_df$feature %in% vars_to_plot, ]
pdp_vianna_se <- ggplot(shap_pdp_plot_df, aes(x=value, y=shap_val)) +
#geom_point() +
ggtitle(expression(~italic(L. (Vianna))~" study effort")) +
stat_smooth(aes(group=iter), color='lightgrey', method='loess', size=0.5, se=FALSE) +
stat_smooth(aes(), method='loess', size=2, se=FALSE) +
geom_rug(data=shap_pdp_plot_df, aes(x=value), alpha=0.3, length=unit(0.05, "npc"), inherit.aes = FALSE, sides='b') +
facet_wrap(~feature, scales='free', ncol=4) +
theme_bw(base_size = 12) +
ylab("Shapley score") +
theme(legend.position = "none")
pdp_vianna_se
ggsave("/Users/carolineglidden/Desktop/reservoir hosts - FINAL/leishmania_vianna/study effort supp/vianna_studyEff_pdps.png", pdp_vianna_se, dpi=600)
library(sf)
sp_points <- read.csv("/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/raw_data/feature_collections/sp_snails/Ponto_Biom_SP_Final.csv")
head(sp_points)
sp_sf_object <- st_as_sf(sp_points, coords = c("Longitude", "Latitude"))
summary(sp_points)
sp_points <- sp_points[complete.cases(sp_points)$Longitude, ]
sp_points <- sp_points[complete.cases(sp_points$Longitude), ]
summary(sp_points)
sp_sf_object <- st_as_sf(sp_points, coords = c("Longitude", "Latitude"))
write_sf(sp_sf_object, "/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/raw_data/feature_collections/sp_snails/sp_snails.shp")
sp_sf_object
write_sf("/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/raw_data/feature_collections/sp_snails/sp_snails.shp", sp_sf_object)
sp_sf_object <- sp_sf_object[,1:21]
names(sp_sf_object)
names(sp_sf_object)[15:18] <- c("year_glabrata", "year_tenagophila", "year_straminea", "year_all")
write_sf(sp_sf_object, "/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/final_data/raw_data/feature_collections/sp_snails/sp_snails.shp")
########maps for Skinner et al. paper on VBD x Human Footprint
library(sf)
library(dplyr)
library(RColorBrewer)
library(dichromat)
library(ggplot2)
library(cmocean)
##------------------------------------##
##read in data & merge to shape files ##
##------------------------------------##
######read in data
data <- read.csv("/Users/carolineglidden/Desktop/forElle/full_dataset.csv"); names(data)[1] <- "CD_MUN_MoH"
mun <- st_read("/Users/carolineglidden/Documents/Leishmania/visceral leishmania spillover - master/machine learning model/raw data/br_municipios_20200807/BR_Municipios_2019.shp")
names(mun)[1] <- "CD_MUN_ibg"
#####match up CD using VL data
vl <- readRDS("/Users/carolineglidden/Documents/Leishmania/visceral leishmania spillover - master/machine learning model/cleaned data/vl data 2001 to 2019.rds")
vl <- unique(vl[, c("CD_MUN_MoH", "CD_MUN_ibg")]); data <- merge(data, vl, by = "CD_MUN_MoH"); mun <- merge(mun, vl, by = "CD_MUN_ibg")
#####attach variables to shape files
full_data <- merge(data, mun, by = 'CD_MUN_MoH')
##------------------------------------##
##covariate plots                     ## ##missing one municipality?
##------------------------------------##
##double check a few rows to make sure below function is correct
avg_human_footprint <- full_data %>%
group_by(CD_MUN_MoH) %>%
summarise(mean_HF = mean(human_footprint), across(.cols = geometry)) %>%
distinct()
hf <- ggplot(data = avg_human_footprint) +
geom_sf(aes(geometry=geometry, fill = mean_HF), col = "white", size=0) +
ggtitle('a. human footprint index') +
scale_fill_distiller(palette = "YlGnBu", direction = 1) +
theme_classic(base_size = 10) +
theme(legend.position = c(0.1, 0.25),
legend.title = element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank())
#ggsave("/Users/carolineglidden/Desktop/forElle/annual_human_footprint.tiff", hf)
avg_human_pop <- full_data %>%
group_by(CD_MUN_MoH) %>%
summarise(mean_pop = mean(population), across(.cols = geometry)) %>%
distinct()
pop <- ggplot(data = avg_human_pop) +
geom_sf(aes(geometry=geometry, fill = log(mean_pop)), col = "white", size=0) +
ggtitle('b. log(population size)') +
#scale_fill_distiller(palette = "YlGnBu", direction = 1) +
scale_fill_cmocean(name='dense') +
theme_classic(base_size = 10) +
theme(legend.position = c(0.1, 0.25),
legend.title = element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank())
#ggsave("/Users/carolineglidden/Desktop/forElle/annual_human_footprint.tiff", hf)
avg_annual_temp <- full_data %>%
group_by(CD_MUN_MoH) %>%
summarise(mean_tmp = mean(annual_tmp), across(.cols = geometry)) %>%
distinct()
temp <- ggplot(data = avg_annual_temp) +
geom_sf(aes(geometry=geometry, fill = mean_tmp), col = "white", size=0) +
ggtitle('c.annual temp') +
scale_fill_distiller(palette = "YlOrRd", direction = 1) +
theme_classic(base_size = 10) +
theme(legend.position = c(0.1, 0.25),
legend.title = element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank())
#ggsave("/Users/carolineglidden/Desktop/forElle/avg_annual_temp.tiff", temp)
avg_forest_cover <- full_data %>%
group_by(CD_MUN_MoH) %>%
summarise(mean_forest = mean(forest), across(.cols = geometry)) %>%
distinct()
frst <- ggplot(data = avg_forest_cover) +
geom_sf(aes(geometry=geometry, fill = mean_forest), col = "white", size=0) +
ggtitle('d. forest cover') +
scale_fill_cmocean(name='algae', start=0.1, end = 0.9) +
#scale_fill_distiller(palette = "Greens", direction = 1) +
theme_classic(base_size = 10) +
theme(legend.position = c(0.1, 0.25),
legend.title = element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank())
#ggsave("/Users/carolineglidden/Desktop/forElle/avg_forest_cover.tiff", frst)
all <- gridExtra::arrangeGrob(hf, pop, temp, frst, ncol=2)
#ggsave("/Users/carolineglidden/Desktop/forElle/vbd_hfi_plots/VBD_LULC_covariates.tiff", supp_all, units = 'in', width = 7, height = 7, dpi = 600)
ggsave("/Users/carolineglidden/Desktop/forElle/vbd_hfi_plots/VBD_LULC_covariates.pdf", supp_all, units = 'in', width = 7, height = 7, dpi = 600)
ggsave("/Users/carolineglidden/Desktop/forElle/vbd_hfi_plots/VBD_LULC_covariates.pdf", all, units = 'in', width = 7, height = 7, dpi = 600)
setwd("~/Documents/GitHub/UPCH-species-distribution-tutorial")
##note that folder structure of the github may have changed since writing this code
library(sf); library(rgbif); library(dplyr); library(raster); library(ggplot2)
dir()
dir('..')
amazon_1km_grid <- st_read("amazon_1km_grid")
amazon_1km_grid <- st_read("../amazon_1km_grid")
amazon_1km_grid$row_code <- seq(1, nrow(amazon_1km_grid), by = 1)
st_write(amazon_1km_grid, "amazon_1km_grid.ship")
st_write(amazon_1km_grid, "amazon_1km_grid.shp")
