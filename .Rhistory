library(raster)
library(rgdal)
library(sp)
library(sf)
setwd("/Users/carolineglidden/Documents/GitHub/prediction_tiffs")
#load land-use maps
#map2010 <- raster("mapbiomas_remap_2010.tiff")
#load raster to create polygons
#base_raster <- raster("/Users/carolineglidden/Desktop/schisto sdm/multi-scale-sdm-schisto/draft_data/env_data/clipped_to_brazil/chelsa_bio17_precip_driest_qt.tif")
#base_polygons <- as(base_raster,'SpatialPolygonsDataFrame')
#base_sf <- st_as_sf(base_polygons)
#base_sf$row_code <- seq(1, nrow(base_sf), by = 1)
#st_write(base_sf, "1km_grid_brazil/1km_grid_brazil.shp")
##now read in lulc data and tack onto shape file
base_sf <- st_read("../amazon_1km_grid")
lulc <- read.csv("amazon_basin_grid_lulc.csv")
lulc$class[lulc$class == 0] <- "not_defined"
lulc$class[lulc$class == 3] <- "forest_formation"
lulc$class[lulc$class == 14] <- "farming"
names(lulc)
lulc_wide <- lulc[,c(2:4)] %>% #group_by(row_code) %>%
#mutate(row = row_number()) %>%
tidyr::pivot_wider(names_from = class, values_from = area)
lulc_wide[is.na(lulc_wide)] <- 0
lulc_wide <- lulc[,c(2:5)] %>% #group_by(row_code) %>%
#mutate(row = row_number()) %>%
tidyr::pivot_wider(names_from = class, values_from = area)
lulc_wide[is.na(lulc_wide)] <- 0
names(lulc)
names(lulc_wide)
lulc <- lulc[lulc$class != 0, ]
lulc <- read.csv("amazon_basin_grid_lulc.csv")
lulc$class[lulc$class == 0] <- "not_defined"
lulc$class[lulc$class == 3] <- "forest_formation"
lulc$class[lulc$class == 14] <- "farming"
lulc <- lulc[lulc$class != 0, ]
lulc_wide <- lulc_wide %>%
pivot_wider(names_from = class, values_from = area)
library(tidyr)
lulc_wide <- lulc_wide %>%
pivot_wider(names_from = class, values_from = area)
lulc_wide <- lulc %>%
pivot_wider(names_from = class, values_from = area)
names(lulc_wide)
lulc_wide
names(lulc)
lulc_wide <- lulc[2:4] %>%
pivot_wider(names_from = class, values_from = area)
lulc_wide
lulc <- read.csv("amazon_basin_grid_lulc.csv")
#---------------------------------------#
#update label for MAPBIOMAS classes     #
#---------------------------------------#
lulc$class[lulc$class == 0] <- "not_defined"
lulc$class[lulc$class == 3] <- "forest_formation"
lulc$class[lulc$class == 14] <- "farming"
lulc <- lulc[lulc$class != 0, ]
lulc_wide <- lulc[2:5] %>%
group_by(row_code) %>%
pivot_wider(names_from = class, values_from = area)
library(dplyr)
lulc_wide <- lulc[2:5] %>%
group_by(row_code) %>%
pivot_wider(names_from = class, values_from = area)
lulc_wide
lulc_wide <- lulc[2:5] %>%
group_by(row_code, year) %>%
pivot_wider(names_from = class, values_from = area)
lulc <- lulc[lulc$class != "not_defined", ]
lulc_wide
lulc_wide <- lulc[2:5] %>%
group_by(row_code, year) %>%
pivot_wider(names_from = class, values_from = area)
lulc_wide
#load libraries
library(tidyr); library(dplyr); library(PerformanceAnalytics); library(spatialsample); library(sf)
#-----------------------------------#
#read in datasets                   #
#-----------------------------------#
mapbiomas <- read.csv("data/a_chamek_ter_mammals_lulc_Oct2022.csv")
climate <- read.csv("data/a_chamek_ter_mammals_climate_Oct2022.csv"); climate <- climate[  c("row_code", "bio13_precip_wettest_month", "cmi_min")]
amazon_basin_pnts <-  read.csv("data/a_chamek_ter_mammals_amazon_thinned_Oct22.csv")
#---------------------------------------#
#update label for MAPBIOMAS classes     #
#---------------------------------------#
#you can look at the classes included in the data using:
unique(mapbiomas$class)
#relabel each class to make it easier to see results
mapbiomas$class[mapbiomas$class == 3] <- "forest_formation"
mapbiomas$class[mapbiomas$class == 14] <- "farming"
#any lulc that was not defined by classIDs in you MAPBIOMAS code will be a zero here, remove these rows
mapbiomas <- mapbiomas[mapbiomas$class != 0, ]
setwd("~/Documents/GitHub/UPCH-species-distribution-tutorial")
#load libraries
library(tidyr); library(dplyr); library(PerformanceAnalytics); library(spatialsample); library(sf)
#-----------------------------------#
#read in datasets                   #
#-----------------------------------#
mapbiomas <- read.csv("data/a_chamek_ter_mammals_lulc_Oct2022.csv")
climate <- read.csv("data/a_chamek_ter_mammals_climate_Oct2022.csv"); climate <- climate[  c("row_code", "bio13_precip_wettest_month", "cmi_min")]
amazon_basin_pnts <-  read.csv("data/a_chamek_ter_mammals_amazon_thinned_Oct22.csv")
#---------------------------------------#
#update label for MAPBIOMAS classes     #
#---------------------------------------#
#you can look at the classes included in the data using:
unique(mapbiomas$class)
#relabel each class to make it easier to see results
mapbiomas$class[mapbiomas$class == 3] <- "forest_formation"
mapbiomas$class[mapbiomas$class == 14] <- "farming"
#any lulc that was not defined by classIDs in you MAPBIOMAS code will be a zero here, remove these rows
mapbiomas <- mapbiomas[mapbiomas$class != 0, ]
mapbiomas_wide <- mapbiomas %>%
pivot_wider(names_from = class, values_from = area)
#change NAs to zero as NA means the land class is not present (so there is 0 area)
mapbiomas_wide[is.na(mapbiomas_wide)] <- 0
mapbiomas_wide
head(mapbiomas)
mapbiomas_wide <- mapbiomas[2:5] %>%
group_by(row_code) %>% mutate(id=row_number()) %>%
pivot_wider(names_from = class, values_from = area)
mapbiomas_wide
mapbiomas_wide <- mapbiomas[2:5] %>%
group_by(row_code) %>%
pivot_wider(names_from = class, values_from = area)
mapbiomas_wide <- mapbiomas[2:5] %>%
group_by(row_code, year) %>%
pivot_wider(names_from = class, values_from = area)
mapbiomas_wide
mapbiomas_wide <- mapbiomas[2:5] %>%
group_by(row_code, year) %>%
mutate(id=row_code)
pivot_wider(names_from = class, values_from = area)
mapbiomas_wide <- mapbiomas[2:5] %>%
mutate(id=row_code)
pivot_wider(id_cols = c(row_code, year), names_from = class, values_from = area)
mapbiomas_wide <- mapbiomas[2:5] %>%
mutate(id=row_code)
pivot_wider(id_cols = c("row_code", "year"), names_from = class, values_from = area)
mapbiomas_wide <- mapbiomas[2:5] %>%
group_by(row_code, year) %>%
pivot_wider(names_from = class, values_from = area)
mapbiomas_wide
mapbiomas_wide <- mapbiomas[2:5] %>%
pivot_wider(names_from = class,
values_from = area,
values_fn = list(area = sum),
values_fill = list(area = 0))
mapbiomas_wide
mapbiomas_mean_diff <- mapbiomas_wide %>%
group_by(row_code) %>%
summarise(
#mean per class
mean_forest = mean(forest_formation),
mean_farming = mean(farming),
#difference over study period per class
diff_forest_formation = forest_formation[match(2020, year)] - forest_formation[match(2001, year)])
write.csv(mapbiomas_mean_diff, "data/a_chamek_ter_mammals_lulc_cleaned_Oct2022.csv")
covariates <- left_join(climate, mapbiomas_mean_diff, by = "row_code")
data0 <- left_join(amazon_basin_pnts, covariates, by = "row_code")
corr <- abs(cor(data0[7:ncol(data0)]))
chart.Correlation(data0[7:ncol(data0)],
histogram = TRUE, method = "pearson")
corr_plot <- chart.Correlation(data0[7:ncol(data0)],
histogram = TRUE, method = "pearson")
ggsave(corr_plot, "/Users/carolineglidden/Documents/GitHub/UPCH-species-distribution-tutorial/final_figures/lulc_correlation.png", dpi = 300)
library(ggplot2)
ggsave(corr_plot, "/Users/carolineglidden/Documents/GitHub/UPCH-species-distribution-tutorial/final_figures/lulc_correlation.png", dpi = 300)
ggsave("/Users/carolineglidden/Documents/GitHub/UPCH-species-distribution-tutorial/final_figures/lulc_correlation.png", corr_plot, dpi = 300)
#convert  analysis_data  to  a  spatial  object
data0_sf  <-  st_as_sf(x  =  data0,
coords  =  c("lon", "lat"),
crs  =  "+proj=longlat +datum=WGS84 +ellps=WGS84")
#identify  groups  of  5  clusters  using  the  spatialsample  package
set.seed(99)  #set  seed  to  get  same  split  each  time
clusters  <-  spatial_block_cv(data0_sf,
method = "random", n = 30, #method for how blocks are oriented in space & number of blocks
relevant_only = TRUE,  v = 3)  #k-means  clustering  to  identify  cross-validation  folds  (3  is  too  few  to  be  robust  but  using  here  to  save  time)
#for  loop  to  create  a  dataframe  that  assigns  a  fold  number  to  each  data  point
splits_df  <-  c()
for(i  in  1:3){
new_df  <-  assessment(clusters$splits[[i]])  #extract  points  in  fold  number  i
new_df$fold  <-  i
new_df  <-  new_df[  c("row_code", "fold")]
splits_df  <-  rbind(splits_df, new_df)  #bind  all  points  x  fold  id  together
}
splits_df  <-  st_drop_geometry(splits_df)  #drop  shapefiles
#final  data  -  merge  cluster  id  to  final  dataset  for  analysis
analysis_data  <-  merge(data0, splits_df, by  =  "row_code")
#sanity  check:  check  how  many  data  points  are  in  each  fold for each response
table(analysis_data$fold, analysis_data$presence)
#write  df  to  save  for  later
write.csv(analysis_data, "data/a_chamek_ter_mammals_finalData_Oct22.csv")
