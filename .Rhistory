no_axis
dir()
ggsave("final_figures/b_tridactylus_sdm_point_distribution.png", point_distribution, dpi = 300)
write.csv(final_pass, "b_tridactylus_ter_mammals_amazon_thinned_Oct22.csv")
write.csv(final_pass, "data/b_tridactylus_ter_mammals_amazon_thinned_Oct22.csv")
ggplot() +
geom_sf(data=ab, color="#2D3E50", fill="lightgrey", size=0.15, show.legend = FALSE) +
geom_jitter(data = final_pass,
aes(x = lon, y = lat, color = species), size = 0.5, alpha = 0.75) +
theme_minimal() +
no_axis
point_distribution <- ggplot() +
geom_sf(data=ab, color="#2D3E50", fill="lightgrey", size=0.15, show.legend = FALSE) +
geom_jitter(data = final_pass,
aes(x = lon, y = lat, color = species), size = 0.5, alpha = 0.75) +
theme_minimal() +
no_axis
ggsave("final_figures/b_tridactylus_sdm_point_distribution.png", point_distribution, dpi = 300)
#load libraries
library(tidyr); library(dplyr); library(PerformanceAnalytics)
#-----------------------------------#
#read in datasets                   #
#-----------------------------------#
occ_data <- read.csv("data/b_tridactylus_ter_mammals_amazon_thinned_Oct22.csv")
mapbiomas <- read.csv("data/b_tridactylus_ter_mammals_lulc_Oct2022.csv")
unique(mapbiomas$class)
length(unique(mapbiomas$class))
#relabel each class to make it easier to see results
mapbiomas$class[mapbiomas$class == 3] <- "forest_formation"
mapbiomas$class[mapbiomas$class == 4] <- "savannah_formation"
mapbiomas$class[mapbiomas$class == 5] <- "mangrove"
mapbiomas$class[mapbiomas$class == 6] <- "flooded_forest"
mapbiomas$class[mapbiomas$class == 11] <- "wetland"
mapbiomas$class[mapbiomas$class == 12] <- "grassland"
mapbiomas$class[mapbiomas$class == 13] <- "non_forested_natural"
mapbiomas$class[mapbiomas$class == 14] <- "farming"
mapbiomas$class[mapbiomas$class == 24] <- "urban"
mapbiomas$class[mapbiomas$class == 25] <- "other_non_vegetated"
mapbiomas$class[mapbiomas$class == 27] <- "not_observed"
mapbiomas$class[mapbiomas$class == 29] <- "rocky_outcrop"
mapbiomas$class[mapbiomas$class == 30] <- "mining"
mapbiomas$class[mapbiomas$class == 33] <- "river_lake_ocean"
mapbiomas_mean <- mapbiomas %>%
group_by(row_code, class) %>%
summarise(mean_area = mean(area))
mapbiomas_mean_wide <- mapbiomas_mean %>%
pivot_wider(names_from = class, values_from = mean_area)
#change NAs to zero as NA means the landclass is not present
mapbiomas_mean_wide[is.na(mapbiomas_mean_wide)] <- 0
mapbiomas_mean_wide
corr <- abs(cor(mapbiomas_mean_wide[2:ncol(mapbiomas_mean_wide)]))
chart.Correlation(mapbiomas_mean_wide[2:ncol(mapbiomas_mean_wide)],
histogram = TRUE, method = "pearson")
write.csv("data/b_tridactylus_ter_mammals_lulc_cleaned_Oct2022.csv")
lulc <- read.csv("data/b_tridactylus_ter_mammals_lulc_cleaned_Oct2022.csv")
amazon_basin_pnts <-  read.csv("data/b_tridactylus_ter_mammals_amazon_thinned_Oct22.csv.csv")
data0 <- left_join(amazon_basin_pnts, lulc, by = "row_code")
library(tidyr); library(dplyr); library(spatialsample); library(sf)
setwd("~/Documents/GitHub/UPCH-species-distribution-tutorial/R_code")
lulc <- read.csv("data/b_tridactylus_ter_mammals_lulc_cleaned_Oct2022.csv")
amazon_basin_pnts <-  read.csv("data/b_tridactylus_ter_mammals_amazon_thinned_Oct22.csv.csv")
data0 <- left_join(amazon_basin_pnts, lulc, by = "row_code")
dir()
lulc <- read.csv("../data/b_tridactylus_ter_mammals_lulc_cleaned_Oct2022.csv")
amazon_basin_pnts <-  read.csv("../data/b_tridactylus_ter_mammals_amazon_thinned_Oct22.csv.csv")
write.csv(mapbiomas_mean_wide, "data/b_tridactylus_ter_mammals_lulc_cleaned_Oct2022.csv")
write.csv(mapbiomas_mean_wide, "../data/b_tridactylus_ter_mammals_lulc_cleaned_Oct2022.csv")
lulc <- read.csv("../data/b_tridactylus_ter_mammals_lulc_cleaned_Oct2022.csv")
amazon_basin_pnts <-  read.csv("../data/b_tridactylus_ter_mammals_amazon_thinned_Oct22.csv")
data0 <- left_join(amazon_basin_pnts, lulc, by = "row_code")
data0_sf <- st_as_sf(x = data0,
coords = c("lon", "lat"),
crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")
#identify groups of 5 clusters using the spatialsample package
clusters <- spatial_clustering_cv(data0_sf, v = 5) #k-means clustering to identify 5 cross-validation folds
#for loop to create a dataframe that assigns a fold number to each data point
splits_df <- c()
for(i in 1:5){
new_df <- assessment(clusters$splits[[i]]) #extract points in fold number i
new_df$fold <- i
new_df <- new_df[,c("row_code", "fold")]
splits_df <- rbind(splits_df, new_df) #bind all points x fold id together
}
splits_df <- st_drop_geometry(splits_df) #drop shapefiles
#final data - merge cluster id to final dataset for analysis
analysis_data <- merge(data0, splits_df, by = "row_code")
#sanity check: check how many data points are in each fold
table(analysis_data$fold)
summary(analysis_data)
names(analysis_data)
write.csv(analysis_data[,8], "../data/b_tridactylus_ter_mammals_finalData_Oct22.csv")
write.csv(analysis_data[,-8], "data/b_tridactylus_ter_mammals_finalData_Oct22.csv")
write.csv(analysis_data[,-8], "../data/b_tridactylus_ter_mammals_finalData_Oct22.csv")
names(analysis_data[,-8])
library(ranger)
setwd("~/Documents/GitHub/UPCH-species-distribution-tutorial")
####random forest species distribution models
library(tidyr); library(dplyr); library(spatialsample); library(sf); library(ranger)
#------------------------------------------------------------------------#
#read in data & merge by row id  (or merge from output of above code)    #
#------------------------------------------------------------------------#
lulc <- read.csv("data/b_tridactylus_ter_mammals_lulc_cleaned_Oct2022.csv")
amazon_basin_pnts <-  read.csv("data/b_tridactylus_ter_mammals_amazon_thinned_Oct22.csv")
data0 <- left_join(amazon_basin_pnts, lulc, by = "row_code")
data0_sf <- st_as_sf(x = data0,
coords = c("lon", "lat"),
crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")
#identify groups of 5 clusters using the spatialsample package
clusters <- spatial_clustering_cv(data0_sf, v = 5) #k-means clustering to identify 5 cross-validation folds
#for loop to create a dataframe that assigns a fold number to each data point
splits_df <- c()
for(i in 1:5){
new_df <- assessment(clusters$splits[[i]]) #extract points in fold number i
new_df$fold <- i
new_df <- new_df[,c("row_code", "fold")]
splits_df <- rbind(splits_df, new_df) #bind all points x fold id together
}
splits_df <- st_drop_geometry(splits_df) #drop shapefiles
#final data - merge cluster id to final dataset for analysis
analysis_data <- merge(data0, splits_df, by = "row_code")
#sanity check: check how many data points are in each fold
table(analysis_data$fold)
rf_performance <- data.frame(model = rep("RF", 5),
fold_id = 1:5,
auc = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
oob_error = rep(NA, 5),
presence = rep(NA, 5), #number of presence points in the fold
background = rep(NA, 5)) #number of bkg points in the fold
names(analysis_data)
hist(analysis_data$farming)
analysis_data$farming
hist(analysis_data$flooded_forest)
names(train_complete)
names(train_complete)
names(train)
names(analysis_data)
hist(analysis_data$grassland)
hist(analysis_data$urban)
hist(analysis_data$wetland)
hist(analysis_data$forest_formation)
hist(analysis_data$river_lake_ocean)
hist(analysis_data$mangrove)
hist(analysis_data$savannah_formation)
hist(analysis_data$rocky_outcrop)
hist(analysis_data$mining)
i <- 1
train <- analysis_data[analysis_data$fold == i, ]
test <- analysis_data[analysis_data$fold != i, ]
train_complete <- train[complete.cases(train),]
test_complete <- test[complete.cases(test),]
hyper_grid <- expand.grid(
mtry       = seq(20, 30, by = 5), #the number of variables to randomly sample as candidates at each split
node_size  = seq(3, 9, by = 3), #minimum number of samples within the terminal nodes
sampe_size = c(.6, .70, .80), #the number of samples to train on
num.trees  = c(500, 1000), #number of trees
OOB_RMSE   = 0
)
for(j in 1:nrow(hyper_grid)) {
# train model
model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid$num.trees[j],
mtry = hyper_grid$mtry[j],
min.node.size = hyper_grid$node_size[j],
sample.fraction = hyper_grid$sampe_size[j],
seed = 123
)
# add OOB error to grid
hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}
hyper_grid <- expand.grid(
mtry       = seq(1, 4, by = 1), #the number of variables to randomly sample as candidates at each split
node_size  = seq(3, 9, by = 3), #minimum number of samples within the terminal nodes
sampe_size = c(.6, .70, .80), #the number of samples to train on
num.trees  = c(500, 1000), #number of trees
OOB_RMSE   = 0
)
#tune model
for(j in 1:nrow(hyper_grid)) {
# train model
model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid$num.trees[j],
mtry = hyper_grid$mtry[j],
min.node.size = hyper_grid$node_size[j],
sample.fraction = hyper_grid$sampe_size[j],
seed = 123
)
# add OOB error to grid
hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}
hyper_grid2 <- hyper_grid %>%
dplyr::arrange(OOB_RMSE)
hyper_grid2
final_model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid2$num.trees[1],
mtry = hyper_grid2$mtry[1],
min.node.size = hyper_grid2$node_size[1],
sample.fraction = hyper_grid2$sampe_size[1],
seed = 123)
pred <- as.data.frame(predict(train_model, newdata=test_complete[,-1], 'prob')) #take out response from test data
train_model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid2$num.trees[1],
mtry = hyper_grid2$mtry[1],
min.node.size = hyper_grid2$node_size[1],
sample.fraction = hyper_grid2$sampe_size[1],
seed = 123)
pred <- as.data.frame(predict(train_model, newdata=test_complete[,-1], 'prob')) #take out response from test data
pred <- as.data.frame(predict(train_model, newdata=test_complete[,c("farming", "urban", "flooded_forest", "forest_formation", "river_lake_ocean")], 'prob')) #take out response from test data
predict(train_model, data = test_complete)
table(analysis_data$fold)
train <- analysis_data[analysis_data$fold != i, ]
test <- analysis_data[analysis_data$fold == i, ]
#remove any rows with NAs bc RF can't handle missing data
train_complete <- train[complete.cases(train),]
test_complete <- test[complete.cases(test),]
hyper_grid <- expand.grid(
mtry       = seq(1, 4, by = 1), #the number of variables to randomly sample as candidates at each split
node_size  = seq(3, 9, by = 3), #minimum number of samples within the terminal nodes
sampe_size = c(.6, .70, .80), #the number of samples to train on
num.trees  = c(500, 1000), #number of trees
OOB_RMSE   = 0
)
#tune model
for(j in 1:nrow(hyper_grid)) {
# train model
model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid$num.trees[j],
mtry = hyper_grid$mtry[j],
min.node.size = hyper_grid$node_size[j],
sample.fraction = hyper_grid$sampe_size[j],
seed = 123
)
# add OOB error to grid
hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}
#arrange the hypergrid so the lowest out-of-bag error (best performing set of parameters) is in the first row
hyper_grid2 <- hyper_grid %>%
dplyr::arrange(OOB_RMSE)
#train model
train_model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid2$num.trees[1],
mtry = hyper_grid2$mtry[1],
min.node.size = hyper_grid2$node_size[1],
sample.fraction = hyper_grid2$sampe_size[1],
seed = 123)
pred <- as.data.frame(predict(train_model, data=test_complete)) #take out response from test data
pred
pred0 <- predict(train_model, data=test_complete)
pred <- pred0$predictions
pred
auc <- pROC::roc(response=as.numeric(test_complete[,"presence"]), predictor=pred, levels=c(1,2), auc = TRUE)
test_complete[,"presence"]
auc <- pROC::roc(response=test_complete[,"presence"], predictor=pred, levels=c(0,1), auc = TRUE)
auc
rf_performance[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,1]==1,1,0)),ifelse(as.numeric(pred[,2])>=best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
metrica.format <- data.frame(cbind(ifelse(test_complete[,"presence"]==1,1,0)),ifelse(pred >= best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_performance[i, "sensitivity"] <- sensitivity
sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_performance[i, "specificity"] <- specificity
rf_performance[i, "oob_error"] <- sdm_rf$err.rate[hyper_grid2$num.trees[1],1]
rf_performance[i, "oob_error"] <- train_model$err.rate[hyper_grid2$num.trees[1],1]
train_model$err.rate
train_model
train_model$prediction.error
?ranger()
#tune model
for(j in 1:nrow(hyper_grid)) {
# train model
model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid$num.trees[j],
mtry = hyper_grid$mtry[j],
min.node.size = hyper_grid$node_size[j],
sample.fraction = hyper_grid$sampe_size[j],
classification = TRUE,
seed = 123
)
# add OOB error to grid
hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}
hyper_grid2 <- hyper_grid %>%
dplyr::arrange(OOB_RMSE)
#train model
train_model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid2$num.trees[1],
mtry = hyper_grid2$mtry[1],
min.node.size = hyper_grid2$node_size[1],
sample.fraction = hyper_grid2$sampe_size[1],
classification = TRUE,
seed = 123)
pred0 <- predict(train_model, data=test_complete); pred <- pred0$predictions
auc <- pROC::roc(response=test_complete[,"presence"], predictor=pred, levels=c(0,1), auc = TRUE)
auc
rf_performance[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,"presence"]==1,1,0)),ifelse(pred >= best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_performance[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_performance[i, "specificity"] <- specificity
rf_performance[i, "oob_error"] <- train_model$prediction.error
rf_performance[i, "presence"] <- nrow(subset(test, presence == 1))
rf_performance[i, "background"] <- nrow(subset(test, presence == 0))
rf_performance
#create empty dataframe to for loop to store results, one row for each fold
rf_performance <- data.frame(model = rep("RF", 5),
fold_id = 1:5,
auc = rep(NA, 5),
sensitivity = rep(NA, 5),
specificity = rep(NA, 5),
oob_error = rep(NA, 5),
presence = rep(NA, 5), #number of presence points in the fold
background = rep(NA, 5)) #number of bkg points in the fold
for(i in 1:5){
train <- analysis_data[analysis_data$fold != i, ]
test <- analysis_data[analysis_data$fold == i, ]
#remove any rows with NAs bc RF can't handle missing data
train_complete <- train[complete.cases(train),]
test_complete <- test[complete.cases(test),]
#------------------------------------#
#define the grid to search over      #
#------------------------------------#
# hyperparameter grid search - keeping it small to save time
# the function below creates a grid with all combinations of parameters
hyper_grid <- expand.grid(
mtry       = seq(1, 4, by = 1), #the number of variables to randomly sample as candidates at each split
node_size  = seq(3, 9, by = 3), #minimum number of samples within the terminal nodes
sampe_size = c(.6, .70, .80), #the number of samples to train on
num.trees  = c(500, 1000), #number of trees
OOB_RMSE   = 0
)
#tune model
for(j in 1:nrow(hyper_grid)) {
# train model
model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid$num.trees[j],
mtry = hyper_grid$mtry[j],
min.node.size = hyper_grid$node_size[j],
sample.fraction = hyper_grid$sampe_size[j],
classification = TRUE,
seed = 123
)
# add OOB error to grid
hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}
#arrange the hypergrid so the lowest out-of-bag error (best performing set of parameters) is in the first row
hyper_grid2 <- hyper_grid %>%
dplyr::arrange(OOB_RMSE)
#train model
train_model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid2$num.trees[1],
mtry = hyper_grid2$mtry[1],
min.node.size = hyper_grid2$node_size[1],
sample.fraction = hyper_grid2$sampe_size[1],
classification = TRUE,
seed = 123)
#save model performance results
pred0 <- predict(train_model, data=test_complete); pred <- pred0$predictions
auc <- pROC::roc(response=test_complete[,"presence"], predictor=pred, levels=c(0,1), auc = TRUE)
rf_performance[i, "auc"] <- auc$auc
best.threshold <- pROC::coords(auc, "best", ret = "threshold")
metrica.format <- data.frame(cbind(ifelse(test_complete[,"presence"]==1,1,0)),ifelse(pred >= best.threshold[1,1],1,0)); colnames(metrica.format) <- c("labels","predictions"); rownames(metrica.format) <- 1:dim(metrica.format)[1]
sensitivity <- metrica::recall(data = metrica.format, obs = labels, pred = predictions)$recall
rf_performance[i, "sensitivity"] <- sensitivity
specificity <- metrica::specificity(data = metrica.format, obs = labels, pred = predictions)$spec
rf_performance[i, "specificity"] <- specificity
rf_performance[i, "oob_error"] <- train_model$prediction.error
rf_performance[i, "presence"] <- nrow(subset(test, presence == 1))
rf_performance[i, "background"] <- nrow(subset(test, presence == 0))
}
rf_performance
i <- 2
train <- analysis_data[analysis_data$fold != i, ]
table(train$presence)
test <- analysis_data[analysis_data$fold == i, ]
table(test$presence)
i <- 3
train <- analysis_data[analysis_data$fold != i, ]
test <- analysis_data[analysis_data$fold == i, ]
table(test$presence)
i <- 4
test <- analysis_data[analysis_data$fold == i, ]
table(test$presence)
i <- 5
test <- analysis_data[analysis_data$fold == i, ]
table(test$presence)
?spatial_clustering_cv
?spatial_block_cv
clusters <- spatial_clustering_cv(data0_sf, v = 3) #k-means clustering to identify 5 cross-validation folds
#for loop to create a dataframe that assigns a fold number to each data point
splits_df <- c()
for(i in 1:3){
new_df <- assessment(clusters$splits[[i]]) #extract points in fold number i
new_df$fold <- i
new_df <- new_df[,c("row_code", "fold")]
splits_df <- rbind(splits_df, new_df) #bind all points x fold id together
}
splits_df <- st_drop_geometry(splits_df) #drop shapefiles
#final data - merge cluster id to final dataset for analysis
analysis_data <- merge(data0, splits_df, by = "row_code")
#sanity check: check how many data points are in each fold
table(analysis_data$fold)
i <- 1
test <- analysis_data[analysis_data$fold == i, ]
table(test$presence)
i <- 2
test <- analysis_data[analysis_data$fold == i, ]
table(test$presence)
i <- 3
table(test$presence)
test <- analysis_data[analysis_data$fold == i, ]
table(test$presence)
rowMeans(rf_performance)
rf_performance
rowMeans(rf_performance[2:ncol(rf_performance)])
names(rf_performance[2:ncol(rf_performance)])
model_performance <- data.frame(metric = names(rf_performance[2:ncol(rf_performance)]),
rowMeans(rf_performance[2:ncol(rf_performance)]))
names(rf_performance[2:ncol(rf_performance)])
model_performance <- data.frame(metric = names(rf_performance)[2:ncol(rf_performance)],
rowMeans(rf_performance[2:ncol(rf_performance)]))
names(rf_performance)[2:ncol(rf_performance)]
rowMeans(rf_performance[2:ncol(rf_performance)])
model_performance <- data.frame(metric = names(rf_performance)[2:ncol(rf_performance)],
colMeans(rf_performance[2:ncol(rf_performance)]))
model_performance
model_performance <- data.frame(metric = names(rf_performance)[2:ncol(rf_performance)],
mean_metric = colMeans(rf_performance[2:ncol(rf_performance)]))
train_model
library(iml); library(ggplot2)
X <- analysis_data[, c("farming", "urban", "flooded_forest", "forest_formation", "river_lake_ocean")]
predictor <- Predictor$new(train_model, data = X, y = analysis_data$presence)
imp <- FeatureImp$new(predictor, loss = "mae")
X
X <- analysis_data[complete.cases(analysis_data), c("farming", "urban", "flooded_forest", "forest_formation", "river_lake_ocean")]
predictor <- Predictor$new(train_model, data = X, y = analysis_data$presence)
predictor <- Predictor$new(train_model, data = X, y = analysis_data[complete.cases(analysis_data),])
predictor <- Predictor$new(train_model, data = X, y = analysis_data[complete.cases(analysis_data), "presence"])
imp <- FeatureImp$new(predictor, loss = "mae")
imp
predictor
?Predictor
train_model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = train_complete,
num.trees = hyper_grid2$num.trees[1],
mtry = hyper_grid2$mtry[1],
min.node.size = hyper_grid2$node_size[1],
sample.fraction = hyper_grid2$sampe_size[1],
classification = TRUE,
importance = 'permutation',
seed = 123)
final_model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = analysis_data[complete.cases(analysis_data)],
num.trees = hyper_grid2$num.trees[1],
mtry = hyper_grid2$mtry[1],
min.node.size = hyper_grid2$node_size[1],
sample.fraction = hyper_grid2$sampe_size[1],
classification = TRUE,
importance = 'permutation',
seed = 123)
final_model <- ranger(
formula = presence ~ farming + urban + flooded_forest + forest_formation + river_lake_ocean,
data = analysis_data[complete.cases(analysis_data),],
num.trees = hyper_grid2$num.trees[1],
mtry = hyper_grid2$mtry[1],
min.node.size = hyper_grid2$node_size[1],
sample.fraction = hyper_grid2$sampe_size[1],
classification = TRUE,
importance = 'permutation',
seed = 123)
final_model$variable.importance
permutation_importance <- as.data.frame(final_model$variable.importance)
permutation_importance
rownames(final_model$variable.importance)
rownames(as.data.frame(final_model$variable.importance))
as.vector(final_model$variable.importance)
permutation_importance <- data.frame(variable = rownames(as.data.frame(final_model$variable.importance)),
importance = as.vector(final_model$variable.importance))
ggplot(permutation_importance, aes(x = variable, y = importance)) +
geom_bar()
ggplot(permutation_importance, aes(x = variable, y = importance)) +
geom_bar(stat="identity")
ggplot(permutation_importance, aes(x = variable, y = importance)) +
geom_bar(stat="identity") +
ggtitle("permutation importance") +
theme_classic()
